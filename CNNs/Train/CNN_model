# -*- coding: utf-8 -*-
"""
Created on Mon Jan 20 09:36:34 2020
2020/01/20 CNN input images 
2020/07/06 add fivefold cross-validation

@author: yue.li
"""

import os
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import RMSprop
from sklearn.model_selection import KFold
import pandas as pd
import datetime
#%% record start time
starttime = datetime.datetime.now()
#%% Parameters
height_width = 150   #image size
image_dir = "train_validation"   #image folder
save_dir = 'saved_models/' # model save folder
kf = KFold(n_splits = 5)   #fivefold cross-validation
epochs_number = 7     
learning_rate = 0.001 
#%% Input data
data = pd.read_csv('train_validation.csv')
data = data.sample(frac=1)   #Shuttle data
Y = data[['label']]  #label
n= data.shape[0]     #number of all columns           
#%% Data argumentation
idg = ImageDataGenerator(
        rescale=1./255,
        rotation_range=1  #int      
        )
#%% defien model name
def get_model_name(k):
    return 'model_'+str(k)+'.h5'
#%% generating model folder
if not os.path.isdir(save_dir):
    os.makedirs(save_dir)
#%% CNN with fivefold cross-validation
# Loss and accuracy
train_accuracy = []
train_loss = []
validation_accuracy = []
validation_loss = []

fold_var = 1 #start value of fivefold cross-validation

for train_index, val_index in kf.split(np.zeros(n),Y):
    print("fold_var=", fold_var)
    training_data = data.iloc[train_index]
    validation_data = data.iloc[val_index]
    
    train_data_generator = idg.flow_from_dataframe(training_data, 
                                                directory = image_dir,
   						       x_col = "filename", y_col = "label",
                            target_size=(height_width, height_width),
                            color_mode='grayscale',
                            batch_size=32,
                            class_mode='binary', 
                            shuffle = True
                            )
    valid_data_generator  = idg.flow_from_dataframe(validation_data, 
                                                  directory = image_dir,
							x_col = "filename", y_col = "label",
                            target_size=(height_width, height_width),
                            color_mode='grayscale',
                            batch_size=32,
                            class_mode='binary', 
                            shuffle = True
                            )
    
    model = tf.keras.models.Sequential([
        tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(height_width, height_width, 1)),     #(3,3) is kernel
        tf.keras.layers.MaxPooling2D((2, 2),padding='valid'),
        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
        tf.keras.layers.MaxPooling2D((2, 2),padding='valid'),
        tf.keras.layers.Conv2D(64, (3,3),activation='relu'),
        tf.keras.layers.MaxPooling2D((2, 2),padding='valid'),
        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
        tf.keras.layers.MaxPooling2D((2, 2),padding='valid'),
        # tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
        # tf.keras.layers.MaxPooling2D((2, 2),padding='valid'),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(512, activation='relu'),   
        tf.keras.layers.Dense(1, activation='sigmoid')   # two kinds   sigmoid; softmax is very bad
        ])
    
    model.compile(loss='binary_crossentropy',
                  optimizer=RMSprop(lr=learning_rate),
                  metrics=['acc'])
   
    history = model.fit(train_data_generator,
			    epochs=epochs_number,
			    validation_data=valid_data_generator)
#%%plot loss   
    acc = history.history['acc']
    val_acc = history.history['val_acc']
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    
    epochs = range(len(acc))
    
    # fig = plt.figure() 
    # plt.plot(epochs, acc, c='deepskyblue', label='Training accuracy')
    # plt.plot(epochs, val_acc, c='orangered', label='Validation accuracy')
    # plt.xlabel("Epochs", fontsize=15)
    # plt.ylabel("Accuracy", fontsize=15)
    # plt.legend(loc='lower right', fontsize=12)
     
    fig = plt.figure() 
    plt.plot(epochs, loss, c='deepskyblue', label='Training Loss')
    plt.plot(epochs, val_loss, c='orangered', label='Validation Loss')
    plt.xlabel("Epochs", fontsize=15)
    plt.ylabel("Loss", fontsize=15)
    plt.xticks(fontsize=12)
    plt.yticks(fontsize=12)
    plt.legend(loc='Upper right', fontsize=12)
    #%% Save model and weights
    model_path = os.path.join(save_dir, get_model_name(fold_var))
    model.save(model_path)

	# LOAD BEST MODEL to evaluate the performance of the model
    model.load_weights(save_dir+get_model_name(fold_var))
	
    results_train = model.evaluate(train_data_generator)
    results_train = dict(zip(model.metrics_names,results_train))
    results_validation = model.evaluate(valid_data_generator)
    results_validation = dict(zip(model.metrics_names,results_validation))
	
    train_accuracy.append(results_train['acc'])
    train_loss.append(results_train['loss'])
    validation_accuracy.append(results_validation['acc'])
    validation_loss.append(results_validation['loss'])
    # Generate generalization metrics
    fold_var += 1

#print average loss values
train_loss_average = np.average(train_loss)
train_loss_std = np.std(train_loss)
print('Train_loss_average=', train_loss_average, 'Train_loss_std=', train_loss_std)
validation_loss_average = np.average(validation_loss)
validation_loss_std = np.std(validation_loss)
print('Validation_loss_average=', validation_loss_average, 'Validation_loss_std=', validation_loss_std)
#%%
endtime = datetime.datetime.now()
print ('Total running time = ', endtime-starttime)
